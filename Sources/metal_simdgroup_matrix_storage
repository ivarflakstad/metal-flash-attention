// -*- Metal -*-
//===-- metal_simdgroup_matrix_storage ------------------------------------===//
// Copyright (c) 2023 Philip Turner. See MIT LICENSE
//===----------------------------------------------------------------------===//


#ifndef __METAL_SIMDGROUP_MATRIX_STORAGE
#define __METAL_SIMDGROUP_MATRIX_STORAGE


// Contains C++ symbols accessible to a developer through automatic code
// completion in Xcode 14.2. Formatted with the same style as the Metal Standard
// Library for consistency with other Metal code.
#include <metal_stdlib>
#if defined(__HAVE_SIMDGROUP_MATRIX__)
#pragma METAL internals : enable

namespace bfloat16_impl {

  template <typename T>
  struct is_float_double {
    constexpr static constant bool value = false;
  };
  template <>
  struct is_float_double<half> {
    constexpr static constant bool value = true;
  };
  template <>
  struct is_float_double<float> {
    constexpr static constant bool value = true;
  };

  union float_raw {
    float f;
    uint32_t i;
  };

  METAL_FUNC uint32_t float_to_raw(float f) {
    float_raw r;
    r.f = f;
    return r.i;
  }

  METAL_FUNC float raw_to_float(uint32_t i) {
    float_raw r;
    r.i = i;
    return r.f;
  }

} /* namespace bfloat16_impl */

namespace metal
{
  
  struct bf16 {
    ushort raw;

    bf16(int raw_) : raw(raw_) {}
    bf16(ushort raw_) : raw(raw_) {}

    bf16() = default;
    METAL_FUNC bf16(float f);
//    template <typename T, typename metal::enable_if_t<is_integral_v<T>>>
//    bf16(T i): bf16(float(i)) {}

    METAL_FUNC operator float() const;
    METAL_FUNC operator ushort() const;

    bf16 operator+() const {
        return *this;
    }
    bf16 operator-() const {
      bf16 h = *this;
      h.raw ^= 0x8000;
      return h;
    }

    bf16 operator++() {
        return (*this = *this + bf16(ushort(1)));
    }
    bf16 operator++(int) {
      bf16 h = *this;
      ++*this;
      return h;
    }
    bf16 operator--() {
      return (*this = *this - bf16(ushort(1)));
    }
    bf16 operator--(int) {
      bf16 h = *this;
      --*this;
      return h;
    }

    friend float operator+(const bf16 h1, const bf16 h2) {
        return float(h1) + float(h2);
    }
    friend float operator-(const bf16 h1, const bf16 h2) {
        return float(h1) - float(h2);
    }
    friend float operator*(const bf16 h1, const bf16 h2) {
        return float(h1) * float(h2);
    }
    friend float operator/(const bf16 h1, const bf16 h2) {
        return float(h1) / float(h2);
    }
    /*
    template <typename T>
    friend typename std::enable_if<std::is_integral<T>::value, float>::type operator+(
        const bfloat16 &h, const T &o) {
        return float(h) + float(o);
    }
    template <typename T>
    friend typename std::enable_if<std::is_integral<T>::value, float>::type operator-(
        const bfloat16 &h, const T &o) {
        return float(h) - float(o);
    }
    template <typename T>
    friend typename std::enable_if<std::is_integral<T>::value, float>::type operator*(
        const bfloat16 &h, const T &o) {
        return float(h) * float(o);
    }
    template <typename T>
    friend typename std::enable_if<std::is_integral<T>::value, float>::type operator/(
        const bfloat16 &h, const T &o) {
        return float(h) / float(o);
    }
    template <typename T>
    friend typename std::enable_if<std::is_integral<T>::value, float>::type operator+(
        const T &o, const bfloat16 &h) {
        return float(o) + float(h);
    }
    template <typename T>
    friend typename std::enable_if<std::is_integral<T>::value, float>::type operator-(
        const T &o, const bfloat16 &h) {
        return float(o) - float(h);
    }
    template <typename T>
    friend typename std::enable_if<std::is_integral<T>::value, float>::type operator*(
        const T &o, const bfloat16 &h) {
        return float(o) * float(h);
    }
    template <typename T>
    friend typename std::enable_if<std::is_integral<T>::value, float>::type operator/(
        const T &o, const bfloat16 &h) {
        return float(o) / float(h);
    }

    template <typename T, typename enable_if_t<bfloat16_impl::is_float_double<T>::value, T>::type>
    friend  operator+(
        const bfloat16 &h, const T &o) {
        return float(h) + o;
    }
    template <typename T>
    friend typename std::enable_if<bfloat16_impl::is_float_double<T>::value, T>::type operator-(
        const bfloat16 &h, const T &o) {
        return float(h) - o;
    }
    template <typename T>
    friend typename std::enable_if<bfloat16_impl::is_float_double<T>::value, T>::type operator*(
        const bfloat16 &h, const T &o) {
        return float(h) * o;
    }
    template <typename T>
    friend typename std::enable_if<bfloat16_impl::is_float_double<T>::value, T>::type operator/(
        const bfloat16 &h, const T &o) {
        return float(h) / o;
    }
    template <typename T>
    friend typename std::enable_if<bfloat16_impl::is_float_double<T>::value, T>::type operator+(
        const T &o, const bfloat16 &h) {
        return o + float(h);
    }
    template <typename T>
    friend typename std::enable_if<bfloat16_impl::is_float_double<T>::value, T>::type operator-(
        const T &o, const bfloat16 &h) {
        return o - float(h);
    }
    template <typename T>
    friend typename std::enable_if<bfloat16_impl::is_float_double<T>::value, T>::type operator*(
        const T &o, const bfloat16 &h) {
        return o * float(h);
    }
    template <typename T>
    friend typename std::enable_if<bfloat16_impl::is_float_double<T>::value, T>::type operator/(
        const T &o, const bfloat16 &h) {
        return o / float(h);
    }
     */

    template <typename T>
    bf16 operator+=(const T o) {
        return *this = bf16(*this + o);
    }
    template <typename T>
    bf16 operator-=(const T o) {
        return *this = bf16(*this - o);
    }
    template <typename T>
    bf16 operator*=(const T o) {
        return *this = bf16(*this * o);
    }
    template <typename T>
    bf16 operator/=(const T o) {
        return *this = bf16(*this / o);
    }
};

bf16::bf16(float f) {
  raw = bfloat16_impl::float_to_raw(f) >> 16; // RTZ
}

METAL_FUNC bf16::operator float() const {
  return bfloat16_impl::raw_to_float(raw << 16);
}

METAL_FUNC bf16::operator ushort() const {
  return raw;
}
  
  template <typename T, typename M = float>
  struct simdgroup_matrix_storage {
    typedef vec<T, 64> storage_type;
    typedef vec<M, 64> multiply_type;
    
    storage_type t;
    
    METAL_FUNC thread vec<T, 2>* thread_elements() thread {
      return reinterpret_cast<thread vec<T, 2>*>(&t);
    }
    
    METAL_FUNC simdgroup_matrix_storage() thread = default;
    
    METAL_FUNC simdgroup_matrix_storage(vec<T, 2> thread_elements) thread {
      *(this->thread_elements()) = thread_elements;
    }
    
    METAL_FUNC static ushort2 offset(ushort thread_index_in_simdgroup) {
      // https://patents.google.com/patent/US11256518B2
      ushort lane_id = thread_index_in_simdgroup;
      ushort quad_id = lane_id / 4;
      
      constexpr ushort QUADRANT_SPAN_M = 4;
      constexpr ushort THREADS_PER_QUADRANT = 8;
      ushort M_floor_of_quadrant = (quad_id / 4) * QUADRANT_SPAN_M;
      ushort M_in_quadrant = (lane_id / 2) % (THREADS_PER_QUADRANT / 2);
      ushort M_in_simd = M_floor_of_quadrant + M_in_quadrant;
      
      ushort N_floor_of_quadrant = (quad_id & 2) * 2; // 0 or 4
      ushort N_in_quadrant = (lane_id % 2) * 2; // 0 or 2
      ushort N_in_simd = N_floor_of_quadrant + N_in_quadrant;
      
      return ushort2(N_in_simd, M_in_simd);
    }
    
    METAL_FUNC static device T* apply_offset(device T *src, uint elements_per_row, uint2 matrix_origin, bool transpose_matrix = false) {
      if (transpose_matrix) {
        return src + ulong(matrix_origin.x * elements_per_row) + matrix_origin.y;
      } else {
        return src + ulong(matrix_origin.y * elements_per_row) + matrix_origin.x;
      }
    }
    
    METAL_FUNC static threadgroup T* apply_offset(threadgroup T *src, ushort elements_per_row, ushort2 matrix_origin, bool transpose_matrix = false) {
      if (transpose_matrix) {
        return src + matrix_origin.x * elements_per_row + matrix_origin.y;
      } else {
        return src + matrix_origin.y * elements_per_row + matrix_origin.x;
      }
    }
    
    // WARNING: All load and store functions assume the X dimension is divisible by 2.
    
    METAL_FUNC void load(const device T *src, uint elements_per_row, ushort2 matrix_origin, bool transpose_matrix = false) {
      if (transpose_matrix) {
        *(thread_elements()) = vec<T, 2>(src[ulong(matrix_origin.x * elements_per_row) + matrix_origin.y], src[ulong((matrix_origin.x + 1) * elements_per_row) + matrix_origin.y]);
      } else {
        *(thread_elements()) = *reinterpret_cast<const device vec<T, 2>*>(src + ulong(matrix_origin.y * elements_per_row) + matrix_origin.x);
      }
    }
    
    METAL_FUNC void load(const threadgroup T *src, ushort elements_per_row, ushort2 matrix_origin, bool transpose_matrix = false) {
      if (transpose_matrix) {
        *(thread_elements()) = vec<T, 2>(src[matrix_origin.x * elements_per_row + matrix_origin.y], src[(matrix_origin.x + 1) * elements_per_row + matrix_origin.y]);
      } else {
        *(thread_elements()) = *reinterpret_cast<const threadgroup vec<T, 2>*>(src + matrix_origin.y * elements_per_row + matrix_origin.x);
      }
    }
    
    METAL_FUNC void load_first(const device T *src, ushort elements_per_row, ushort2 matrix_origin, bool transpose_matrix = false) {
      if (transpose_matrix) {
        thread_elements()[0][0] = src[matrix_origin.x * elements_per_row + matrix_origin.y];
      } else {
        thread_elements()[0][0] = src[matrix_origin.y * elements_per_row + matrix_origin.x];
      }
    }
    
    METAL_FUNC void load_second(const device T *src, ushort elements_per_row, ushort2 matrix_origin, bool transpose_matrix = false) {
      if (transpose_matrix) {
        thread_elements()[0][1] = src[matrix_origin.x * elements_per_row + matrix_origin.y];
      } else {
        thread_elements()[0][1] = src[matrix_origin.y * elements_per_row + matrix_origin.x];
      }
    }
    
    METAL_FUNC void store(device T *dst, uint elements_per_row, ushort2 matrix_origin, bool transpose_matrix = false) {
      if (transpose_matrix) {
        dst[ulong(matrix_origin.x * elements_per_row) + matrix_origin.y] = thread_elements()[0][0];
        dst[ulong((matrix_origin.x + 1) * elements_per_row) + matrix_origin.y] = thread_elements()[0][1];
      } else {
        *reinterpret_cast<device vec<T, 2>*>(dst + matrix_origin.y * elements_per_row + matrix_origin.x) = *(thread_elements());
      }
    }
    
    METAL_FUNC void store_first(device T *dst, uint elements_per_row, ushort2 matrix_origin, bool transpose_matrix = false) {
      if (transpose_matrix) {
        dst[ulong(matrix_origin.x * elements_per_row) + matrix_origin.y] = thread_elements()[0][0];
      } else {
        dst[matrix_origin.y * elements_per_row + matrix_origin.x] = thread_elements()[0][0];
      }
    }
    
    METAL_FUNC void store_second(device T *dst, uint elements_per_row, ushort2 matrix_origin, bool transpose_matrix = false) {
      if (transpose_matrix) {
        dst[ulong(matrix_origin.x * elements_per_row) + matrix_origin.y] = thread_elements()[0][1];
      } else {
        dst[matrix_origin.y * elements_per_row + matrix_origin.x] = thread_elements()[0][1];
      }
    }
    
    METAL_FUNC void store(threadgroup T *dst, ushort elements_per_row, ushort2 matrix_origin, bool transpose_matrix = false) {
      if (transpose_matrix) {
        dst[matrix_origin.x * elements_per_row + matrix_origin.y] = thread_elements()[0][0];
        dst[(matrix_origin.x + 1) * elements_per_row + matrix_origin.y] = thread_elements()[0][1];
      } else {
        *reinterpret_cast<threadgroup vec<T, 2>*>(dst + matrix_origin.y * elements_per_row + matrix_origin.x) = *(thread_elements());
      }
    }
    
    template <typename U, typename V>
    METAL_FUNC void multiply(simdgroup_matrix_storage<U> a, simdgroup_matrix_storage<V> b, bool accumulate = true) {
      if (!accumulate) {
        *(thread_elements()) = vec<T, 2>(0);
      }
      t = __metal_simdgroup_matrix_8x8_multiply_accumulate(a.t, b.t, t, typename simdgroup_matrix_storage<T>::storage_type());
    }
    
    constexpr METAL_FUNC ushort float_to_bfloat_bits(float x) {
      // Check for nan
      if ((as_type<uint>(x) & ~_fp_encoding_traits<float>::sign_mask) > _fp_encoding_traits<float>::inf_mask) {
        return ushort(as_type<uint>(0x7FC0));
      }
      // Take bits
      uint float_bits = as_type<uint>(x);

      // Round to nearest even
      float_bits += ((float_bits >> 16) & 1) + as_type<uint>(0x7FFF);

      
      // Take upper 16 bits
      return float_bits >> 16;
    }
    
    constexpr METAL_FUNC float bfloat_bits_to_float(ushort x) {
      return as_type<float>((uint)x << 16);
    }
    
    constexpr METAL_FUNC vec<ushort, 64> __float_to_bfloat_bits(vec<float, 64> x) {
        vec<ushort, 64> result = {};
        #pragma clang loop unroll(full)
        for (uint i = 0; i < 64; i += 1) {
          result[i] = bf16(x[i]);
        }
        return result;
    }
    
    constexpr METAL_FUNC vec<ushort, 64> float_to_bfloat_bits(vec<float, 64> x) {
        vec<ushort, 64> result = {};
        #pragma clang loop unroll(full)
        for (uint i = 0; i < 64; i += 1) {
          result[i] = bf16(x[i]);
        }
        return result;
    }
    
    constexpr METAL_FUNC vec<float, 64> bfloat_bits_to_float(vec<ushort, 64> x) {
      vec<float, 64> result = {};
      #pragma clang loop unroll(full)
      for (uint i = 0; i < 64; i += 1) {
        result[i] = bf16(x[i]);
      }
      return result;
    }
    
    
    METAL_FUNC void multiply(simdgroup_matrix_storage<ushort> a, simdgroup_matrix_storage<ushort> b, bool accumulate = true) {
      if (!accumulate) {
        *(thread_elements()) = vec<T, 2>(0);
      }
      
      t = float_to_bfloat_bits(__metal_simdgroup_matrix_8x8_multiply_accumulate(
                                                           bfloat_bits_to_float(a.t),
                                                           bfloat_bits_to_float(b.t),
                                                           bfloat_bits_to_float(t),
                                                           typename simdgroup_matrix_storage<T>::multiply_type()
                                                           ));
    }
    // 'bfloat' is 'float' with the lower 16 bits set to garbage (BF15).
    
    METAL_FUNC thread ushort4* thread_elements_bfloat() thread {
      thread float2* elements = thread_elements();
      return reinterpret_cast<thread ushort4*>(elements);
    }
    
    METAL_FUNC simdgroup_matrix_storage<float> unpack_bfloat() thread {
      ushort4 output;
      thread ushort2& elements = thread_elements();
      output.y = elements[0];
      output.w = elements[1];
      return simdgroup_matrix_storage(as_type<float2>(output));
    }
    
    METAL_FUNC simdgroup_matrix_storage<ushort> pack_bfloat() thread {
      thread ushort4* elements = thread_elements_bfloat();
      return simdgroup_matrix_storage(ushort2(elements->y, elements->w));
    }
    
    METAL_FUNC void load_bfloat(const threadgroup ushort *src, ushort elements_per_row, ushort2 matrix_origin, bool transpose_matrix = false) {
      if (transpose_matrix) {
        thread_elements_bfloat()->y = src[matrix_origin.x * elements_per_row + matrix_origin.y];
        thread_elements_bfloat()->w = src[(matrix_origin.x + 1) * elements_per_row + matrix_origin.y];
      } else {
        thread_elements_bfloat()->zw = *reinterpret_cast<const threadgroup ushort2*>(src + matrix_origin.y * elements_per_row + matrix_origin.x);
        thread_elements_bfloat()->y = thread_elements_bfloat()->z;
      }
    }
    
    METAL_FUNC void store_bfloat(threadgroup ushort *dst, ushort elements_per_row, ushort2 matrix_origin, bool transpose_matrix = false) {
      if (transpose_matrix) {
        dst[matrix_origin.x * elements_per_row + matrix_origin.y] = *(thread_elements_bfloat()).y;
        dst[(matrix_origin.x + 1) * elements_per_row + matrix_origin.y] = *(thread_elements_bfloat()).w;
      } else {
        *(thread_elements_bfloat()).z = *(thread_elements_bfloat()).y;
        *reinterpret_cast<threadgroup vec<T, 2>*>(dst + matrix_origin.y * elements_per_row + matrix_origin.x) = *(thread_elements_bfloat()).zw;
      }
    }
  };
} // namespace metal
#pragma METAL internals : disable
#endif

#endif // __METAL_SIMDGROUP_MATRIX_STORAGE
